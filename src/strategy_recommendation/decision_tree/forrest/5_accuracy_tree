digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname="helvetica"] ;
edge [fontname="helvetica"] ;
0 [label=<percentile &le; 4.369<br/>gini = 0.736<br/>samples = 39<br/>value = [1, 6, 3, 18, 3, 2, 1, 4, 1]<br/>class = ALIPY_QBC>, fillcolor="#b7f6d1"] ;
1 [label=<number of negative covariance &le; 35.109<br/>gini = 0.718<br/>samples = 29<br/>value = [1, 0, 3, 14, 3, 2, 1, 4, 1]<br/>class = ALIPY_QBC>, fillcolor="#b0f5cd"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<percentile &le; 0.721<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 2, 1]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#f29ceb"] ;
1 -> 2 ;
3 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 2, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#e539d7"] ;
2 -> 3 ;
4 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 1]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#e53964"] ;
2 -> 4 ;
5 [label=<number of examples &le; 2.516<br/>gini = 0.669<br/>samples = 26<br/>value = [1, 0, 3, 14, 3, 2, 1, 2, 0]<br/>class = ALIPY_QBC>, fillcolor="#a0f3c3"] ;
1 -> 5 ;
6 [label=<kurtosis mean &le; 0.389<br/>gini = 0.75<br/>samples = 8<br/>value = [1, 0, 3, 2, 1, 0, 0, 1, 0]<br/>class = PLAYGROUND_MIXTURE>, fillcolor="#e5fbde"] ;
5 -> 6 ;
7 [label=<column cosine similarity mean &le; 0.272<br/>gini = 0.72<br/>samples = 5<br/>value = [1, 0, 0, 2, 1, 0, 0, 1, 0]<br/>class = ALIPY_QBC>, fillcolor="#cef8e0"] ;
6 -> 7 ;
8 [label=<number of features &le; 0.724<br/>gini = 0.667<br/>samples = 3<br/>value = [1, 0, 0, 0, 1, 0, 0, 1, 0]<br/>class = PLAYGROUND_MIXTURE>, fillcolor="#ffffff"] ;
7 -> 8 ;
9 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#e539d7"] ;
8 -> 9 ;
10 [label=<number of examples &le; 2.275<br/>gini = 0.5<br/>samples = 2<br/>value = [1, 0, 0, 0, 1, 0, 0, 0, 0]<br/>class = PLAYGROUND_MIXTURE>, fillcolor="#ffffff"] ;
8 -> 10 ;
11 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#39d7e5"] ;
10 -> 11 ;
12 [label=<gini = 0.0<br/>samples = 1<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_MIXTURE>, fillcolor="#e58139"] ;
10 -> 12 ;
13 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 2, 0, 0, 0, 0, 0]<br/>class = ALIPY_QBC>, fillcolor="#39e581"] ;
7 -> 13 ;
14 [label=<gini = 0.0<br/>samples = 3<br/>value = [0, 0, 3, 0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_MIXTURE>, fillcolor="#64e539"] ;
6 -> 14 ;
15 [label=<examples feature_ratio &le; 0.001<br/>gini = 0.525<br/>samples = 18<br/>value = [0, 0, 0, 12, 2, 2, 1, 1, 0]<br/>class = ALIPY_QBC>, fillcolor="#83efb0"] ;
5 -> 15 ;
16 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#e539d7"] ;
15 -> 16 ;
17 [label=<coefficient variation mean &le; 0.915<br/>gini = 0.471<br/>samples = 17<br/>value = [0, 0, 0, 12, 2, 2, 1, 0, 0]<br/>class = ALIPY_QBC>, fillcolor="#7beeab"] ;
15 -> 17 ;
18 [label=<entropy mean &le; 0.5<br/>gini = 0.406<br/>samples = 16<br/>value = [0, 0, 0, 12, 2, 2, 0, 0, 0]<br/>class = ALIPY_QBC>, fillcolor="#72eca5"] ;
17 -> 18 ;
19 [label=<percentile &le; -1.181<br/>gini = 0.64<br/>samples = 5<br/>value = [0, 0, 0, 2, 1, 2, 0, 0, 0]<br/>class = ALIPY_QBC>, fillcolor="#ffffff"] ;
18 -> 19 ;
20 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 2, 0, 0, 0, 0, 0]<br/>class = ALIPY_QBC>, fillcolor="#39e581"] ;
19 -> 20 ;
21 [label=<number of examples &le; 2.857<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 0, 0, 0, 1, 2, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#9cb2f2"] ;
19 -> 21 ;
22 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#39d7e5"] ;
21 -> 22 ;
23 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 2, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#3964e5"] ;
21 -> 23 ;
24 [label=<feature dummy 2 &le; 6220.0<br/>gini = 0.165<br/>samples = 11<br/>value = [0, 0, 0, 10, 1, 0, 0, 0, 0]<br/>class = ALIPY_QBC>, fillcolor="#4de88e"] ;
18 -> 24 ;
25 [label=<gini = 0.0<br/>samples = 9<br/>value = [0, 0, 0, 9, 0, 0, 0, 0, 0]<br/>class = ALIPY_QBC>, fillcolor="#39e581"] ;
24 -> 25 ;
26 [label=<feature dummy 2 &le; 6890.5<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 1, 1, 0, 0, 0, 0]<br/>class = ALIPY_QBC>, fillcolor="#ffffff"] ;
24 -> 26 ;
27 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#39d7e5"] ;
26 -> 27 ;
28 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 1, 0, 0, 0, 0, 0]<br/>class = ALIPY_QBC>, fillcolor="#39e581"] ;
26 -> 28 ;
29 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 1, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#8139e5"] ;
17 -> 29 ;
30 [label=<feature dummy 1 &le; 3.5<br/>gini = 0.48<br/>samples = 10<br/>value = [0, 6, 0, 4, 0, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#f2f6bd"] ;
0 -> 30 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
31 [label=<gini = 0.0<br/>samples = 4<br/>value = [0, 4, 0, 0, 0, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#d7e539"] ;
30 -> 31 ;
32 [label=<quantile mean &le; 0.012<br/>gini = 0.444<br/>samples = 6<br/>value = [0, 2, 0, 4, 0, 0, 0, 0, 0]<br/>class = ALIPY_QBC>, fillcolor="#9cf2c0"] ;
30 -> 32 ;
33 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 1, 0, 0, 0, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#d7e539"] ;
32 -> 33 ;
34 [label=<number of examples &le; 2.31<br/>gini = 0.32<br/>samples = 5<br/>value = [0, 1, 0, 4, 0, 0, 0, 0, 0]<br/>class = ALIPY_QBC>, fillcolor="#6aeca0"] ;
32 -> 34 ;
35 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 1, 0, 0, 0, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#d7e539"] ;
34 -> 35 ;
36 [label=<gini = 0.0<br/>samples = 4<br/>value = [0, 0, 0, 4, 0, 0, 0, 0, 0]<br/>class = ALIPY_QBC>, fillcolor="#39e581"] ;
34 -> 36 ;
}
