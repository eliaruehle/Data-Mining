digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname="helvetica"] ;
edge [fontname="helvetica"] ;
0 [label=<overall mean &le; 0.22<br/>gini = 0.899<br/>samples = 39<br/>value = [1, 2, 6, 2, 1, 1, 2, 2, 1, 1, 1, 1, 7, 2<br/>2, 6, 1]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#fcf9fe"] ;
1 [label=<gini = 0.0<br/>samples = 3<br/>value = [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#d1e539"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<number of examples &le; 2.307<br/>gini = 0.903<br/>samples = 36<br/>value = [1, 2, 3, 2, 1, 1, 2, 2, 1, 1, 1, 1, 7, 2<br/>2, 6, 1]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#fcf8fe"] ;
0 -> 2 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
3 [label=<coefficient variation mean &le; 0.54<br/>gini = 0.64<br/>samples = 5<br/>value = [0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2<br/>0, 0, 0]<br/>class = SKACTIVEML_QUIRE>, fillcolor="#ffffff"] ;
2 -> 3 ;
4 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2<br/>0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#e539e5"] ;
3 -> 4 ;
5 [label=<percentile &le; -0.372<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = SKACTIVEML_QUIRE>, fillcolor="#f2de9c"] ;
3 -> 5 ;
6 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = SKACTIVEML_QUIRE>, fillcolor="#e5bd39"] ;
5 -> 6 ;
7 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#39e595"] ;
5 -> 7 ;
8 [label=<number of positive covariance &le; 0.949<br/>gini = 0.88<br/>samples = 31<br/>value = [1, 0, 3, 2, 1, 1, 1, 2, 1, 1, 1, 1, 7, 0<br/>2, 6, 1]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#fcf7fe"] ;
2 -> 8 ;
9 [label=<feature dummy 2 &le; 18.0<br/>gini = 0.865<br/>samples = 28<br/>value = [1, 0, 1, 2, 1, 1, 1, 2, 1, 1, 1, 0, 7, 0<br/>2, 6, 1]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#fbf6fe"] ;
8 -> 9 ;
10 [label=<entropy mean &le; 6.5<br/>gini = 0.797<br/>samples = 16<br/>value = [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 3, 0<br/>1, 6, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#f9d1dd"] ;
9 -> 10 ;
11 [label=<range mean &le; 0.497<br/>gini = 0.861<br/>samples = 12<br/>value = [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 3, 0<br/>1, 2, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#f6ebfc"] ;
10 -> 11 ;
12 [label=<number of positive covariance &le; 0.885<br/>gini = 0.781<br/>samples = 8<br/>value = [0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 3, 0<br/>1, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#e6c6f8"] ;
11 -> 12 ;
13 [label=<range mean &le; 0.262<br/>gini = 0.56<br/>samples = 5<br/>value = [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0<br/>0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#d49cf2"] ;
12 -> 13 ;
14 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#39e595"] ;
13 -> 14 ;
15 [label=<quantile mean &le; 0.083<br/>gini = 0.375<br/>samples = 4<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0<br/>0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#c67bee"] ;
13 -> 15 ;
16 [label=<gini = 0.0<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0<br/>0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#a939e5"] ;
15 -> 16 ;
17 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#d1e539"] ;
15 -> 17 ;
18 [label=<percentile &le; -0.416<br/>gini = 0.667<br/>samples = 3<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0<br/>1, 0, 0]<br/>class = LIBACT_QUIRE>, fillcolor="#ffffff"] ;
12 -> 18 ;
19 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = LIBACT_QUIRE>, fillcolor="#58e539"] ;
18 -> 19 ;
20 [label=<entropy mean &le; 0.5<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0<br/>1, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#ffffff"] ;
18 -> 20 ;
21 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>1, 0, 0]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#e539a9"] ;
20 -> 21 ;
22 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0<br/>0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#3944e5"] ;
20 -> 22 ;
23 [label=<kurtosis mean &le; -0.015<br/>gini = 0.625<br/>samples = 4<br/>value = [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 2, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#f6bdce"] ;
11 -> 23 ;
24 [label=<kurtosis mean &le; -0.115<br/>gini = 0.5<br/>samples = 2<br/>value = [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = ALIPY_UNCERTAINTY_ENTROPY>, fillcolor="#ffffff"] ;
23 -> 24 ;
25 [label=<gini = 0.0<br/>samples = 1<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = ALIPY_UNCERTAINTY_ENTROPY>, fillcolor="#e58139"] ;
24 -> 25 ;
26 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#95e539"] ;
24 -> 26 ;
27 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 2, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#e5396d"] ;
23 -> 27 ;
28 [label=<gini = 0.0<br/>samples = 4<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 4, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#e5396d"] ;
10 -> 28 ;
29 [label=<number of examples &le; 2.991<br/>gini = 0.819<br/>samples = 12<br/>value = [0, 0, 0, 1, 0, 1, 0, 2, 1, 1, 0, 0, 4, 0<br/>1, 0, 1]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#eed7fa"] ;
9 -> 29 ;
30 [label=<range mean &le; 0.322<br/>gini = 0.656<br/>samples = 8<br/>value = [0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 4, 0<br/>0, 0, 1]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#e2bdf6"] ;
29 -> 30 ;
31 [label=<quantile mean &le; 0.025<br/>gini = 0.667<br/>samples = 3<br/>value = [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0<br/>0, 0, 1]<br/>class = LIBACT_DWUS>, fillcolor="#ffffff"] ;
30 -> 31 ;
32 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#39e5d1"] ;
31 -> 32 ;
33 [label=<overall mean &le; 0.328<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 1]<br/>class = LIBACT_DWUS>, fillcolor="#ffffff"] ;
31 -> 33 ;
34 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 1]<br/>class = SKACTIVEML_VOI>, fillcolor="#e54139"] ;
33 -> 34 ;
35 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#95e539"] ;
33 -> 35 ;
36 [label=<percentile &le; -0.463<br/>gini = 0.32<br/>samples = 5<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 4, 0<br/>0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#be6aec"] ;
30 -> 36 ;
37 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#39e5d1"] ;
36 -> 37 ;
38 [label=<gini = 0.0<br/>samples = 4<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0<br/>0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#a939e5"] ;
36 -> 38 ;
39 [label=<column cosine similarity mean &le; 0.095<br/>gini = 0.75<br/>samples = 4<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0<br/>1, 0, 0]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#ffffff"] ;
29 -> 39 ;
40 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#39bde5"] ;
39 -> 40 ;
41 [label=<examples feature_ratio &le; 0.011<br/>gini = 0.667<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0<br/>1, 0, 0]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#ffffff"] ;
39 -> 41 ;
42 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#39e556"] ;
41 -> 42 ;
43 [label=<entropy mean &le; 3363.0<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0<br/>1, 0, 0]<br/>class = ALIPY_GRAPH_DENSITY>, fillcolor="#ffffff"] ;
41 -> 43 ;
44 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = ALIPY_GRAPH_DENSITY>, fillcolor="#3981e5"] ;
43 -> 44 ;
45 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>1, 0, 0]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#e539a9"] ;
43 -> 45 ;
46 [label=<column cosine similarity mean &le; 0.297<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0<br/>0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#e8f29c"] ;
8 -> 46 ;
47 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0<br/>0, 0, 0]<br/>class = SMALLTEXT_GREEDYCORESET>, fillcolor="#6a39e5"] ;
46 -> 47 ;
48 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#d1e539"] ;
46 -> 48 ;
}
