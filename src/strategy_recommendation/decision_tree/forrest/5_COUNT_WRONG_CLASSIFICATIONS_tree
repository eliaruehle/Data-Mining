digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname="helvetica"] ;
edge [fontname="helvetica"] ;
0 [label=<number of examples &le; 2.611<br/>gini = 0.508<br/>samples = 39<br/>value = [2, 1, 1, 27, 1, 1, 1, 1, 1, 3]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#7bee94"] ;
1 [label=<coefficient variation mean &le; 0.634<br/>gini = 0.861<br/>samples = 12<br/>value = [2, 1, 1, 0, 1, 1, 1, 1, 1, 3]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#fcebee"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<number of examples &le; 2.331<br/>gini = 0.75<br/>samples = 8<br/>value = [2, 0, 0, 0, 0, 1, 1, 1, 0, 3]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#fbdee3"] ;
1 -> 2 ;
3 [label=<number of examples &le; 2.101<br/>gini = 0.611<br/>samples = 6<br/>value = [2, 0, 0, 0, 0, 0, 0, 1, 0, 3]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#f8ced5"] ;
2 -> 3 ;
4 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#a339e5"] ;
3 -> 4 ;
5 [label=<number of negative covariance &le; 72.94<br/>gini = 0.48<br/>samples = 5<br/>value = [2, 0, 0, 0, 0, 0, 0, 0, 0, 3]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#f6bdc7"] ;
3 -> 5 ;
6 [label=<feature dummy 3 &le; 3.719<br/>gini = 0.444<br/>samples = 3<br/>value = [2, 0, 0, 0, 0, 0, 0, 0, 0, 1]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#f2c09c"] ;
5 -> 6 ;
7 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#e53958"] ;
6 -> 7 ;
8 [label=<gini = 0.0<br/>samples = 2<br/>value = [2, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#e58139"] ;
6 -> 8 ;
9 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 2]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#e53958"] ;
5 -> 9 ;
10 [label=<quantile mean &le; 0.036<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 1, 1, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#ffffff"] ;
2 -> 10 ;
11 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#399de5"] ;
10 -> 11 ;
12 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#3c39e5"] ;
10 -> 12 ;
13 [label=<number of examples &le; 2.312<br/>gini = 0.75<br/>samples = 4<br/>value = [0, 1, 1, 0, 1, 0, 0, 0, 1, 0]<br/>class = SKACTIVEML_QUIRE>, fillcolor="#ffffff"] ;
1 -> 13 ;
14 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#39e5c5"] ;
13 -> 14 ;
15 [label=<feature dummy 2 &le; 9.0<br/>gini = 0.667<br/>samples = 3<br/>value = [0, 1, 1, 0, 0, 0, 0, 0, 1, 0]<br/>class = SKACTIVEML_QUIRE>, fillcolor="#ffffff"] ;
13 -> 15 ;
16 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_QUIRE>, fillcolor="#e2e539"] ;
15 -> 16 ;
17 [label=<entropy mean &le; 197.5<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 1, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#ffffff"] ;
15 -> 17 ;
18 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]<br/>class = ALIPY_UNCERTAINTY_LC>, fillcolor="#e539c0"] ;
17 -> 18 ;
19 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#7be539"] ;
17 -> 19 ;
20 [label=<gini = 0.0<br/>samples = 27<br/>value = [0, 0, 0, 27, 0, 0, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#39e55e"] ;
0 -> 20 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
}
