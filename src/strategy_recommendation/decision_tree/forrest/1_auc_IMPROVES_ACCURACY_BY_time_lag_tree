digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname="helvetica"] ;
edge [fontname="helvetica"] ;
0 [label=<number of features &le; 1.679<br/>gini = 0.934<br/>samples = 39<br/>value = [1, 3, 2, 1, 1, 3, 3, 1, 1, 1, 2, 1, 1, 1<br/>1, 5, 1, 2, 4, 3, 1]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#fdf9fe"] ;
1 [label=<number of examples &le; 3.728<br/>gini = 0.92<br/>samples = 33<br/>value = [1, 0, 1, 1, 1, 3, 3, 1, 1, 1, 2, 0, 1, 0<br/>1, 5, 1, 2, 4, 3, 1]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#fcf8fe"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<feature dummy 3 &le; 1.996<br/>gini = 0.911<br/>samples = 28<br/>value = [1, 0, 1, 1, 1, 3, 2, 1, 1, 1, 1, 0, 1, 0<br/>1, 5, 1, 2, 4, 0, 1]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#fcf7fe"] ;
1 -> 2 ;
3 [label=<feature dummy 1 &le; 5.0<br/>gini = 0.625<br/>samples = 4<br/>value = [1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = ALIPY_CORESET_GREEDY>, fillcolor="#bdf6c4"] ;
2 -> 3 ;
4 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = ALIPY_CORESET_GREEDY>, fillcolor="#39e54d"] ;
3 -> 4 ;
5 [label=<percentile &le; 0.214<br/>gini = 0.5<br/>samples = 2<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = ALIPY_QBC>, fillcolor="#ffffff"] ;
3 -> 5 ;
6 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#39b7e5"] ;
5 -> 6 ;
7 [label=<gini = 0.0<br/>samples = 1<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = ALIPY_QBC>, fillcolor="#e58139"] ;
5 -> 7 ;
8 [label=<coefficient variation mean &le; 0.751<br/>gini = 0.889<br/>samples = 24<br/>value = [0, 0, 1, 1, 1, 3, 0, 1, 1, 1, 0, 0, 1, 0<br/>1, 5, 1, 2, 4, 0, 1]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#fbf5fe"] ;
2 -> 8 ;
9 [label=<number of positive covariance &le; 0.649<br/>gini = 0.893<br/>samples = 22<br/>value = [0, 0, 1, 1, 1, 3, 0, 1, 1, 1, 0, 0, 1, 0<br/>1, 5, 1, 2, 2, 0, 1]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#f7eafc"] ;
8 -> 9 ;
10 [label=<number of positive covariance &le; 0.591<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_QBC>, fillcolor="#aaf29c"] ;
9 -> 10 ;
11 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#86e539"] ;
10 -> 11 ;
12 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_QBC>, fillcolor="#56e539"] ;
10 -> 12 ;
13 [label=<variance mean &le; 0.268<br/>gini = 0.881<br/>samples = 19<br/>value = [0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0<br/>1, 5, 1, 2, 2, 0, 1]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#f1dcfa"] ;
9 -> 13 ;
14 [label=<quantile mean &le; 0.031<br/>gini = 0.883<br/>samples = 16<br/>value = [0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0<br/>1, 4, 1, 0, 2, 0, 1]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#f4e3fb"] ;
13 -> 14 ;
15 [label=<number of positive covariance &le; 0.753<br/>gini = 0.667<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0<br/>1, 0, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_CONTRASTIVEAL>, fillcolor="#ffffff"] ;
14 -> 15 ;
16 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>1, 0, 0, 0, 0, 0, 0]<br/>class = LIBACT_QUIRE>, fillcolor="#7e39e5"] ;
15 -> 16 ;
17 [label=<number of examples &le; 3.24<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_CONTRASTIVEAL>, fillcolor="#ffffff"] ;
15 -> 17 ;
18 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_CONTRASTIVEAL>, fillcolor="#39e57e"] ;
17 -> 18 ;
19 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_VOI_UNLABELED>, fillcolor="#39e5e2"] ;
17 -> 19 ;
20 [label=<kurtosis mean &le; 1.327<br/>gini = 0.84<br/>samples = 13<br/>value = [0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0<br/>0, 4, 1, 0, 2, 0, 1]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#f1dbfa"] ;
14 -> 20 ;
21 [label=<number of negative covariance &le; 48.279<br/>gini = 0.876<br/>samples = 11<br/>value = [0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0<br/>0, 2, 1, 0, 2, 0, 1]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#ffffff"] ;
20 -> 21 ;
22 [label=<overall mean &le; 0.509<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 2, 1, 0, 0, 0, 0]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#d89cf2"] ;
21 -> 22 ;
23 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 2, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#b139e5"] ;
22 -> 23 ;
24 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 1, 0, 0, 0, 0]<br/>class = ALIPY_GRAPH_DENSITY>, fillcolor="#e239e5"] ;
22 -> 24 ;
25 [label=<column cosine similarity mean &le; 0.284<br/>gini = 0.844<br/>samples = 8<br/>value = [0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0<br/>0, 0, 0, 0, 2, 0, 1]<br/>class = PLAYGROUND_UNIFORM>, fillcolor="#fbe3ee"] ;
21 -> 25 ;
26 [label=<percentile &le; -1.004<br/>gini = 0.833<br/>samples = 6<br/>value = [0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0<br/>0, 0, 0, 0, 0, 0, 1]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#ffffff"] ;
25 -> 26 ;
27 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_QBC>, fillcolor="#56e539"] ;
26 -> 27 ;
28 [label=<skewness mean &le; 0.312<br/>gini = 0.8<br/>samples = 5<br/>value = [0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0<br/>0, 0, 0, 0, 0, 0, 1]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#ffffff"] ;
26 -> 28 ;
29 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 1]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#e54d39"] ;
28 -> 29 ;
30 [label=<overall mean &le; 0.379<br/>gini = 0.75<br/>samples = 4<br/>value = [0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#ffffff"] ;
28 -> 30 ;
31 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_LIGHTWEIGHTCORESET>, fillcolor="#3956e5"] ;
30 -> 31 ;
32 [label=<number of negative covariance &le; 53.22<br/>gini = 0.667<br/>samples = 3<br/>value = [0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#ffffff"] ;
30 -> 32 ;
33 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#e5e239"] ;
32 -> 33 ;
34 [label=<feature dummy 3 &le; 4.108<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#ffffff"] ;
32 -> 34 ;
35 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#b7e539"] ;
34 -> 35 ;
36 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#39e5b1"] ;
34 -> 36 ;
37 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 2, 0, 0]<br/>class = PLAYGROUND_UNIFORM>, fillcolor="#e53986"] ;
25 -> 37 ;
38 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 2, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#b139e5"] ;
20 -> 38 ;
39 [label=<coefficient variation mean &le; 0.746<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 1, 0, 2, 0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#f29cdb"] ;
13 -> 39 ;
40 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 2, 0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#e539b7"] ;
39 -> 40 ;
41 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 1, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#b139e5"] ;
39 -> 41 ;
42 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 2, 0, 0]<br/>class = PLAYGROUND_UNIFORM>, fillcolor="#e53986"] ;
8 -> 42 ;
43 [label=<feature dummy 3 &le; 6.964<br/>gini = 0.56<br/>samples = 5<br/>value = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0<br/>0, 0, 0, 0, 0, 3, 0]<br/>class = SMALLTEXT_GREEDYCORESET>, fillcolor="#f29caa"] ;
1 -> 43 ;
44 [label=<number of negative covariance &le; 62.919<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = ALIPY_CORESET_GREEDY>, fillcolor="#ffffff"] ;
43 -> 44 ;
45 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = ALIPY_CORESET_GREEDY>, fillcolor="#39e54d"] ;
44 -> 45 ;
46 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#39b7e5"] ;
44 -> 46 ;
47 [label=<gini = 0.0<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 3, 0]<br/>class = SMALLTEXT_GREEDYCORESET>, fillcolor="#e53956"] ;
43 -> 47 ;
48 [label=<variance mean &le; 0.209<br/>gini = 0.667<br/>samples = 6<br/>value = [0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#f5e0b0"] ;
0 -> 48 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
49 [label=<gini = 0.0<br/>samples = 3<br/>value = [0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#e5b139"] ;
48 -> 49 ;
50 [label=<number of positive covariance &le; 0.479<br/>gini = 0.667<br/>samples = 3<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#ffffff"] ;
48 -> 50 ;
51 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#3986e5"] ;
50 -> 51 ;
52 [label=<number of examples &le; 3.249<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#ffffff"] ;
50 -> 52 ;
53 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#4d39e5"] ;
52 -> 53 ;
54 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#e5e239"] ;
52 -> 54 ;
}
