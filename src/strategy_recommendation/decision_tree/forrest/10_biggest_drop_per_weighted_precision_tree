digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname="helvetica"] ;
edge [fontname="helvetica"] ;
0 [label=<number of examples &le; 3.583<br/>gini = 0.861<br/>samples = 39<br/>value = [6, 1, 1, 5, 10, 4, 1, 1, 5, 1, 1, 1, 1, 1]<br/>class = SMALLTEXT_PREDICTIONENTROPY>, fillcolor="#e7fce9"] ;
1 [label=<number of negative covariance &le; 72.018<br/>gini = 0.809<br/>samples = 30<br/>value = [0, 1, 1, 5, 10, 4, 1, 1, 5, 1, 0, 0, 0, 1]<br/>class = SMALLTEXT_PREDICTIONENTROPY>, fillcolor="#d7fadb"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<feature dummy 3 &le; 3.37<br/>gini = 0.842<br/>samples = 19<br/>value = [0, 1, 0, 4, 2, 4, 1, 1, 4, 1, 0, 0, 0, 1]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#ffffff"] ;
1 -> 2 ;
3 [label=<gini = 0.0<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_10>, fillcolor="#3956e5"] ;
2 -> 3 ;
4 [label=<number of positive covariance &le; 0.816<br/>gini = 0.836<br/>samples = 16<br/>value = [0, 1, 0, 4, 2, 4, 1, 1, 1, 1, 0, 0, 0, 1]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#ffffff"] ;
2 -> 4 ;
5 [label=<gini = 0.0<br/>samples = 3<br/>value = [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#6de539"] ;
4 -> 5 ;
6 [label=<number of positive covariance &le; 0.874<br/>gini = 0.84<br/>samples = 13<br/>value = [0, 1, 0, 1, 2, 4, 1, 1, 1, 1, 0, 0, 0, 1]<br/>class = OPTIMAL_GREEDY_10>, fillcolor="#dbfaec"] ;
4 -> 6 ;
7 [label=<number of positive covariance &le; 0.823<br/>gini = 0.32<br/>samples = 5<br/>value = [0, 0, 0, 0, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_10>, fillcolor="#6aecb2"] ;
6 -> 7 ;
8 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_PREDICTIONENTROPY>, fillcolor="#39e54d"] ;
7 -> 8 ;
9 [label=<gini = 0.0<br/>samples = 4<br/>value = [0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_10>, fillcolor="#39e598"] ;
7 -> 9 ;
10 [label=<quantile mean &le; 0.031<br/>gini = 0.875<br/>samples = 8<br/>value = [0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1]<br/>class = PLAYGROUND_GRAPH_DENSITY>, fillcolor="#ffffff"] ;
6 -> 10 ;
11 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_PREDICTIONENTROPY>, fillcolor="#39e54d"] ;
10 -> 11 ;
12 [label=<number of negative covariance &le; 41.41<br/>gini = 0.857<br/>samples = 7<br/>value = [0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1]<br/>class = PLAYGROUND_GRAPH_DENSITY>, fillcolor="#ffffff"] ;
10 -> 12 ;
13 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]<br/>class = SKACTIVEML_EXPECTED_AVERAGE_PRECISION>, fillcolor="#6739e5"] ;
12 -> 13 ;
14 [label=<skewness mean &le; 0.443<br/>gini = 0.833<br/>samples = 6<br/>value = [0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1]<br/>class = PLAYGROUND_GRAPH_DENSITY>, fillcolor="#ffffff"] ;
12 -> 14 ;
15 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_GRAPH_DENSITY>, fillcolor="#e5c839"] ;
14 -> 15 ;
16 [label=<column cosine similarity mean &le; 0.249<br/>gini = 0.8<br/>samples = 5<br/>value = [0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#ffffff"] ;
14 -> 16 ;
17 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_10>, fillcolor="#3956e5"] ;
16 -> 17 ;
18 [label=<feature dummy 1 &le; 0.5<br/>gini = 0.75<br/>samples = 4<br/>value = [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#ffffff"] ;
16 -> 18 ;
19 [label=<kurtosis mean &le; -0.015<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#ffffff"] ;
18 -> 19 ;
20 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]<br/>class = OPTIMAL_GREEDY_10>, fillcolor="#e5393c"] ;
19 -> 20 ;
21 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#6de539"] ;
19 -> 21 ;
22 [label=<range mean &le; 0.485<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_VOI_LABELED>, fillcolor="#ffffff"] ;
18 -> 22 ;
23 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_GRAPH_DENSITY>, fillcolor="#399de5"] ;
22 -> 23 ;
24 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_VOI_LABELED>, fillcolor="#39e5e2"] ;
22 -> 24 ;
25 [label=<number of features &le; 0.827<br/>gini = 0.446<br/>samples = 11<br/>value = [0, 0, 1, 1, 8, 0, 0, 0, 1, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_PREDICTIONENTROPY>, fillcolor="#74ed82"] ;
1 -> 25 ;
26 [label=<range mean &le; 0.262<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#ffffff"] ;
25 -> 26 ;
27 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#6de539"] ;
26 -> 27 ;
28 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_10>, fillcolor="#3956e5"] ;
26 -> 28 ;
29 [label=<percentile &le; -0.224<br/>gini = 0.198<br/>samples = 9<br/>value = [0, 0, 1, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_PREDICTIONENTROPY>, fillcolor="#52e863"] ;
25 -> 29 ;
30 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_MC_EER_MISCLASS_LOSS>, fillcolor="#b7e539"] ;
29 -> 30 ;
31 [label=<gini = 0.0<br/>samples = 8<br/>value = [0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_PREDICTIONENTROPY>, fillcolor="#39e54d"] ;
29 -> 31 ;
32 [label=<number of features &le; 0.5<br/>gini = 0.519<br/>samples = 9<br/>value = [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#efb083"] ;
0 -> 32 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
33 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#b139e5"] ;
32 -> 33 ;
34 [label=<total harmonic meanstandard deviation_mean &le; 0.96<br/>gini = 0.406<br/>samples = 8<br/>value = [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#eca572"] ;
32 -> 34 ;
35 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#e539d1"] ;
34 -> 35 ;
36 [label=<entropy mean &le; 521.5<br/>gini = 0.245<br/>samples = 7<br/>value = [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#e9965a"] ;
34 -> 36 ;
37 [label=<gini = 0.0<br/>samples = 5<br/>value = [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#e58139"] ;
36 -> 37 ;
38 [label=<number of examples &le; 3.78<br/>gini = 0.5<br/>samples = 2<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#ffffff"] ;
36 -> 38 ;
39 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#e53986"] ;
38 -> 39 ;
40 [label=<gini = 0.0<br/>samples = 1<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#e58139"] ;
38 -> 40 ;
}
