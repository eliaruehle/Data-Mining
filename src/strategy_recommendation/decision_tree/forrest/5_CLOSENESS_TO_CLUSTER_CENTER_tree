digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname="helvetica"] ;
edge [fontname="helvetica"] ;
0 [label=<number of examples &le; 3.583<br/>gini = 0.876<br/>samples = 39<br/>value = [6, 5, 2, 3, 1, 1, 2, 9, 1, 3, 4, 1, 1]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#edf3fd"] ;
1 [label=<entropy mean &le; 64.5<br/>gini = 0.889<br/>samples = 30<br/>value = [6, 3, 2, 3, 1, 1, 2, 3, 1, 3, 4, 0, 1]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#fdf5f0"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<number of positive covariance &le; 0.677<br/>gini = 0.875<br/>samples = 21<br/>value = [1, 3, 0, 2, 0, 1, 2, 3, 1, 3, 4, 0, 1]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#fef4fd"] ;
1 -> 2 ;
3 [label=<column cosine similarity mean &le; 0.203<br/>gini = 0.375<br/>samples = 4<br/>value = [0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#7ba5ee"] ;
2 -> 3 ;
4 [label=<gini = 0.0<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#3978e5"] ;
3 -> 4 ;
5 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]<br/>class = SMALLTEXT_PREDICTIONENTROPY>, fillcolor="#4a39e5"] ;
3 -> 5 ;
6 [label=<feature dummy 3 &le; 2.946<br/>gini = 0.844<br/>samples = 17<br/>value = [1, 3, 0, 2, 0, 1, 2, 0, 0, 3, 4, 0, 1]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#fdf1fd"] ;
2 -> 6 ;
7 [label=<gini = 0.0<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#e539e2"] ;
6 -> 7 ;
8 [label=<coefficient variation mean &le; 0.746<br/>gini = 0.847<br/>samples = 14<br/>value = [1, 3, 0, 2, 0, 1, 2, 0, 0, 3, 1, 0, 1]<br/>class = SMALLTEXT_CONTRASTIVEAL>, fillcolor="#ffffff"] ;
6 -> 8 ;
9 [label=<quantile mean &le; 0.031<br/>gini = 0.819<br/>samples = 12<br/>value = [1, 3, 0, 2, 0, 1, 0, 0, 0, 3, 1, 0, 1]<br/>class = SMALLTEXT_CONTRASTIVEAL>, fillcolor="#ffffff"] ;
8 -> 9 ;
10 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_CONTRASTIVEAL>, fillcolor="#e5ce39"] ;
9 -> 10 ;
11 [label=<column cosine similarity mean &le; 0.27<br/>gini = 0.82<br/>samples = 10<br/>value = [1, 1, 0, 2, 0, 1, 0, 0, 0, 3, 1, 0, 1]<br/>class = ALIPY_CORESET_GREEDY>, fillcolor="#f2e6fc"] ;
9 -> 11 ;
12 [label=<variance mean &le; 0.279<br/>gini = 0.56<br/>samples = 5<br/>value = [0, 1, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0]<br/>class = ALIPY_CORESET_GREEDY>, fillcolor="#cc9cf2"] ;
11 -> 12 ;
13 [label=<number of positive covariance &le; 0.894<br/>gini = 0.375<br/>samples = 4<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0]<br/>class = ALIPY_CORESET_GREEDY>, fillcolor="#bc7bee"] ;
12 -> 13 ;
14 [label=<gini = 0.0<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0]<br/>class = ALIPY_CORESET_GREEDY>, fillcolor="#9a39e5"] ;
13 -> 14 ;
15 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#39e5b4"] ;
13 -> 15 ;
16 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_CONTRASTIVEAL>, fillcolor="#e5ce39"] ;
12 -> 16 ;
17 [label=<skewness mean &le; 0.506<br/>gini = 0.72<br/>samples = 5<br/>value = [1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#d6f8ce"] ;
11 -> 17 ;
18 [label=<number of negative covariance &le; 55.437<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#adf29c"] ;
17 -> 18 ;
19 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#5be539"] ;
18 -> 19 ;
20 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#e539e2"] ;
18 -> 20 ;
21 [label=<number of examples &le; 2.662<br/>gini = 0.5<br/>samples = 2<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#ffffff"] ;
17 -> 21 ;
22 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]<br/>class = SMALLTEXT_CONTRASTIVEAL>, fillcolor="#e53941"] ;
21 -> 22 ;
23 [label=<gini = 0.0<br/>samples = 1<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#e58139"] ;
21 -> 23 ;
24 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#39c5e5"] ;
8 -> 24 ;
25 [label=<column cosine similarity mean &le; 0.216<br/>gini = 0.617<br/>samples = 9<br/>value = [5, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#f4c9aa"] ;
1 -> 25 ;
26 [label=<number of examples &le; 2.303<br/>gini = 0.278<br/>samples = 6<br/>value = [5, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#ea9a61"] ;
25 -> 26 ;
27 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#ace539"] ;
26 -> 27 ;
28 [label=<gini = 0.0<br/>samples = 5<br/>value = [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#e58139"] ;
26 -> 28 ;
29 [label=<percentile &le; 1.028<br/>gini = 0.667<br/>samples = 3<br/>value = [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#ffffff"] ;
25 -> 29 ;
30 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#ace539"] ;
29 -> 30 ;
31 [label=<examples feature_ratio &le; 0.184<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#ffffff"] ;
29 -> 31 ;
32 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#39e564"] ;
31 -> 32 ;
33 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#5be539"] ;
31 -> 33 ;
34 [label=<number of positive covariance &le; 0.947<br/>gini = 0.494<br/>samples = 9<br/>value = [0, 2, 0, 0, 0, 0, 0, 6, 0, 0, 0, 1, 0]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#8eb2f0"] ;
0 -> 34 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
35 [label=<feature dummy 2 &le; 5228.5<br/>gini = 0.278<br/>samples = 6<br/>value = [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 1, 0]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#6193ea"] ;
34 -> 35 ;
36 [label=<gini = 0.0<br/>samples = 5<br/>value = [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#3978e5"] ;
35 -> 36 ;
37 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]<br/>class = PLAYGROUND_MARGIN>, fillcolor="#e53992"] ;
35 -> 37 ;
38 [label=<feature dummy 3 &le; 7.603<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_CONTRASTIVEAL>, fillcolor="#f2e69c"] ;
34 -> 38 ;
39 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SMALLTEXT_CONTRASTIVEAL>, fillcolor="#e5ce39"] ;
38 -> 39 ;
40 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#3978e5"] ;
38 -> 40 ;
}
