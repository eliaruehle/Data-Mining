digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname="helvetica"] ;
edge [fontname="helvetica"] ;
0 [label=<number of examples &le; 2.716<br/>gini = 0.869<br/>samples = 39<br/>value = [2, 1, 11, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1<br/>2, 1, 2, 7, 1]<br/>class = PLAYGROUND_MARGIN>, fillcolor="#fbfce6"] ;
1 [label=<number of positive covariance &le; 0.903<br/>gini = 0.272<br/>samples = 13<br/>value = [0, 0, 11, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 1, 0, 0, 0]<br/>class = PLAYGROUND_MARGIN>, fillcolor="#e4e95a"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<percentile &le; -0.372<br/>gini = 0.153<br/>samples = 12<br/>value = [0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 1, 0, 0, 0]<br/>class = PLAYGROUND_MARGIN>, fillcolor="#e2e74b"] ;
1 -> 2 ;
3 [label=<column cosine similarity mean &le; 0.249<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 1, 0, 0, 0]<br/>class = PLAYGROUND_MARGIN>, fillcolor="#ffffff"] ;
2 -> 3 ;
4 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 1, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#e539cb"] ;
3 -> 4 ;
5 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = PLAYGROUND_MARGIN>, fillcolor="#dfe539"] ;
3 -> 5 ;
6 [label=<gini = 0.0<br/>samples = 10<br/>value = [0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = PLAYGROUND_MARGIN>, fillcolor="#dfe539"] ;
2 -> 6 ;
7 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = SMALLTEXT_LIGHTWEIGHTCORESET>, fillcolor="#72e539"] ;
1 -> 7 ;
8 [label=<number of examples &le; 3.151<br/>gini = 0.888<br/>samples = 26<br/>value = [2, 1, 0, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1<br/>2, 0, 2, 7, 1]<br/>class = LIBACT_DWUS>, fillcolor="#fad6dd"] ;
0 -> 8 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
9 [label=<feature dummy 3 &le; 6.009<br/>gini = 0.889<br/>samples = 12<br/>value = [0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1<br/>2, 0, 2, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#ffffff"] ;
8 -> 9 ;
10 [label=<variance mean &le; 0.242<br/>gini = 0.844<br/>samples = 8<br/>value = [0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1<br/>2, 0, 0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#f7e3fb"] ;
9 -> 10 ;
11 [label=<examples feature_ratio &le; 0.016<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1<br/>2, 0, 0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#e49cf2"] ;
10 -> 11 ;
12 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>2, 0, 0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#c839e5"] ;
11 -> 12 ;
13 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1<br/>0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#9239e5"] ;
11 -> 13 ;
14 [label=<number of features &le; 0.628<br/>gini = 0.8<br/>samples = 5<br/>value = [0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0<br/>0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#ffffff"] ;
10 -> 14 ;
15 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#3983e5"] ;
14 -> 15 ;
16 [label=<number of negative covariance &le; 74.685<br/>gini = 0.75<br/>samples = 4<br/>value = [0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0<br/>0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#ffffff"] ;
14 -> 16 ;
17 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#e5b439"] ;
16 -> 17 ;
18 [label=<feature dummy 3 &le; 1.771<br/>gini = 0.667<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0<br/>0, 0, 0, 0, 0]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#ffffff"] ;
16 -> 18 ;
19 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0<br/>0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#5b39e5"] ;
18 -> 19 ;
20 [label=<feature dummy 3 &le; 2.287<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#ffffff"] ;
18 -> 20 ;
21 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#39e5a3"] ;
20 -> 21 ;
22 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = PLAYGROUND_HIERARCHICAL_CLUSTER>, fillcolor="#39bae5"] ;
20 -> 22 ;
23 [label=<entropy mean &le; 0.5<br/>gini = 0.625<br/>samples = 4<br/>value = [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 2, 0, 0]<br/>class = ALIPY_CORESET_GREEDY>, fillcolor="#f6bddc"] ;
9 -> 23 ;
24 [label=<range mean &le; 0.506<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#ffffff"] ;
23 -> 24 ;
25 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#a9e539"] ;
24 -> 25 ;
26 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = SMALLTEXT_GREEDYCORESET>, fillcolor="#39e56d"] ;
24 -> 26 ;
27 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 2, 0, 0]<br/>class = ALIPY_CORESET_GREEDY>, fillcolor="#e53995"] ;
23 -> 27 ;
28 [label=<examples feature_ratio &le; 0.001<br/>gini = 0.704<br/>samples = 14<br/>value = [2, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0<br/>0, 0, 0, 7, 1]<br/>class = LIBACT_DWUS>, fillcolor="#f4acbc"] ;
8 -> 28 ;
29 [label=<number of negative covariance &le; 37.075<br/>gini = 0.667<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 1]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#ffffff"] ;
28 -> 29 ;
30 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#3ce539"] ;
29 -> 30 ;
31 [label=<skewness mean &le; 0.488<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 1]<br/>class = LIBACT_DWUS>, fillcolor="#ffffff"] ;
29 -> 31 ;
32 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#39e5da"] ;
31 -> 32 ;
33 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 1]<br/>class = SMALLTEXT_GREEDYCORESET>, fillcolor="#e54a39"] ;
31 -> 33 ;
34 [label=<number of positive covariance &le; 0.95<br/>gini = 0.545<br/>samples = 11<br/>value = [2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0<br/>0, 0, 0, 7, 0]<br/>class = LIBACT_DWUS>, fillcolor="#f191a6"] ;
28 -> 34 ;
35 [label=<percentile &le; -1.204<br/>gini = 0.37<br/>samples = 9<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0<br/>0, 0, 0, 7, 0]<br/>class = LIBACT_DWUS>, fillcolor="#ec6a86"] ;
34 -> 35 ;
36 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = PLAYGROUND_HIERARCHICAL_CLUSTER>, fillcolor="#39bae5"] ;
35 -> 36 ;
37 [label=<entropy mean &le; 6160.0<br/>gini = 0.219<br/>samples = 8<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 7, 0]<br/>class = LIBACT_DWUS>, fillcolor="#e95575"] ;
35 -> 37 ;
38 [label=<gini = 0.0<br/>samples = 6<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 6, 0]<br/>class = LIBACT_DWUS>, fillcolor="#e5395e"] ;
37 -> 38 ;
39 [label=<kurtosis mean &le; 0.819<br/>gini = 0.5<br/>samples = 2<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 1, 0]<br/>class = SMALLTEXT_CONTRASTIVEAL>, fillcolor="#ffffff"] ;
37 -> 39 ;
40 [label=<gini = 0.0<br/>samples = 1<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = SMALLTEXT_CONTRASTIVEAL>, fillcolor="#e58139"] ;
39 -> 40 ;
41 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 1, 0]<br/>class = LIBACT_DWUS>, fillcolor="#e5395e"] ;
39 -> 41 ;
42 [label=<entropy mean &le; 392.0<br/>gini = 0.5<br/>samples = 2<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = SMALLTEXT_CONTRASTIVEAL>, fillcolor="#ffffff"] ;
34 -> 42 ;
43 [label=<gini = 0.0<br/>samples = 1<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = SMALLTEXT_CONTRASTIVEAL>, fillcolor="#e58139"] ;
42 -> 43 ;
44 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0<br/>0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#394de5"] ;
42 -> 44 ;
}
