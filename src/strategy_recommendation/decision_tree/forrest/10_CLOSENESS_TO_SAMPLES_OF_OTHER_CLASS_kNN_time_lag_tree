digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname="helvetica"] ;
edge [fontname="helvetica"] ;
0 [label=<number of examples &le; 2.928<br/>gini = 0.728<br/>samples = 39<br/>value = [2, 19, 2, 3, 1, 1, 1, 1, 2, 1, 1, 5]<br/>class = LIBACT_DWUS>, fillcolor="#f4efad"] ;
1 [label=<number of positive covariance &le; 0.904<br/>gini = 0.185<br/>samples = 20<br/>value = [0, 18, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#e8db4e"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<column cosine similarity mean &le; 0.089<br/>gini = 0.1<br/>samples = 19<br/>value = [0, 18, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#e6d944"] ;
1 -> 2 ;
3 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#9de539"] ;
2 -> 3 ;
4 [label=<gini = 0.0<br/>samples = 18<br/>value = [0, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#e5d739"] ;
2 -> 4 ;
5 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = LIBACT_EER>, fillcolor="#47e539"] ;
1 -> 5 ;
6 [label=<entropy mean &le; 61.0<br/>gini = 0.875<br/>samples = 19<br/>value = [2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 5]<br/>class = LIBACT_DWUS>, fillcolor="#fadcdf"] ;
0 -> 6 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
7 [label=<number of negative covariance &le; 36.125<br/>gini = 0.893<br/>samples = 11<br/>value = [1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0]<br/>class = LIBACT_DWUS>, fillcolor="#f2ebfc"] ;
6 -> 7 ;
8 [label=<percentile &le; 0.496<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#c09cf2"] ;
7 -> 8 ;
9 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#8139e5"] ;
8 -> 9 ;
10 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#9de539"] ;
8 -> 10 ;
11 [label=<kurtosis mean &le; -0.199<br/>gini = 0.875<br/>samples = 8<br/>value = [1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0]<br/>class = LIBACT_DWUS>, fillcolor="#ffffff"] ;
7 -> 11 ;
12 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]<br/>class = SKACTIVEML_DWUS>, fillcolor="#e5399d"] ;
11 -> 12 ;
13 [label=<number of negative covariance &le; 37.075<br/>gini = 0.857<br/>samples = 7<br/>value = [1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#ffffff"] ;
11 -> 13 ;
14 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#39e5d7"] ;
13 -> 14 ;
15 [label=<percentile &le; -1.225<br/>gini = 0.833<br/>samples = 6<br/>value = [1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#ffffff"] ;
13 -> 15 ;
16 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]<br/>class = LIBACT_QUIRE>, fillcolor="#3947e5"] ;
15 -> 16 ;
17 [label=<feature dummy 3 &le; 6.499<br/>gini = 0.8<br/>samples = 5<br/>value = [1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#ffffff"] ;
15 -> 17 ;
18 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = LIBACT_EER>, fillcolor="#47e539"] ;
17 -> 18 ;
19 [label=<variance mean &le; 0.231<br/>gini = 0.75<br/>samples = 4<br/>value = [1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#ffffff"] ;
17 -> 19 ;
20 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]<br/>class = SKACTIVEML_DWUS>, fillcolor="#d739e5"] ;
19 -> 20 ;
21 [label=<column cosine similarity mean &le; 0.246<br/>gini = 0.667<br/>samples = 3<br/>value = [1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#ffffff"] ;
19 -> 21 ;
22 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]<br/>class = ALIPY_GRAPH_DENSITY>, fillcolor="#399de5"] ;
21 -> 22 ;
23 [label=<overall mean &le; 0.499<br/>gini = 0.5<br/>samples = 2<br/>value = [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#ffffff"] ;
21 -> 23 ;
24 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_COST_EMBEDDING>, fillcolor="#39e581"] ;
23 -> 24 ;
25 [label=<gini = 0.0<br/>samples = 1<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#e58139"] ;
23 -> 25 ;
26 [label=<percentile &le; 1.453<br/>gini = 0.562<br/>samples = 8<br/>value = [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5]<br/>class = LIBACT_DWUS>, fillcolor="#f08e96"] ;
6 -> 26 ;
27 [label=<gini = 0.0<br/>samples = 4<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4]<br/>class = LIBACT_DWUS>, fillcolor="#e53947"] ;
26 -> 27 ;
28 [label=<number of examples &le; 3.331<br/>gini = 0.75<br/>samples = 4<br/>value = [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]<br/>class = LIBACT_DWUS>, fillcolor="#ffffff"] ;
26 -> 28 ;
29 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#e5d739"] ;
28 -> 29 ;
30 [label=<percentile &le; 121.432<br/>gini = 0.667<br/>samples = 3<br/>value = [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]<br/>class = LIBACT_DWUS>, fillcolor="#ffffff"] ;
28 -> 30 ;
31 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = LIBACT_EER>, fillcolor="#47e539"] ;
30 -> 31 ;
32 [label=<number of features &le; 2.056<br/>gini = 0.5<br/>samples = 2<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]<br/>class = LIBACT_DWUS>, fillcolor="#ffffff"] ;
30 -> 32 ;
33 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]<br/>class = LIBACT_DWUS>, fillcolor="#e53947"] ;
32 -> 33 ;
34 [label=<gini = 0.0<br/>samples = 1<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#e58139"] ;
32 -> 34 ;
}
