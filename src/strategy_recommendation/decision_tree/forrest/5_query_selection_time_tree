digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname="helvetica"] ;
edge [fontname="helvetica"] ;
0 [label=<number of examples &le; 3.396<br/>gini = 0.819<br/>samples = 39<br/>value = [4, 5, 1, 5, 2, 3, 1, 13, 5]<br/>class = SKACTIVEML_MC_EER_MISCLASS_LOSS>, fillcolor="#f9d0f6"] ;
1 [label=<feature dummy 3 &le; 1.763<br/>gini = 0.707<br/>samples = 28<br/>value = [1, 0, 0, 5, 1, 3, 0, 13, 5]<br/>class = SKACTIVEML_MC_EER_MISCLASS_LOSS>, fillcolor="#f6baf1"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<gini = 0.0<br/>samples = 3<br/>value = [0, 0, 0, 3, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_VOI_UNLABELED>, fillcolor="#39e581"] ;
1 -> 2 ;
3 [label=<number of negative covariance &le; 39.551<br/>gini = 0.666<br/>samples = 25<br/>value = [1, 0, 0, 2, 1, 3, 0, 13, 5]<br/>class = SKACTIVEML_MC_EER_MISCLASS_LOSS>, fillcolor="#f5b0ef"] ;
1 -> 3 ;
4 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 2, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_VOI_UNLABELED>, fillcolor="#39e581"] ;
3 -> 4 ;
5 [label=<skewness mean &le; 0.215<br/>gini = 0.612<br/>samples = 23<br/>value = [1, 0, 0, 0, 1, 3, 0, 13, 5]<br/>class = SKACTIVEML_MC_EER_MISCLASS_LOSS>, fillcolor="#f3a7ed"] ;
3 -> 5 ;
6 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 2]<br/>class = SKACTIVEML_VOI>, fillcolor="#e53964"] ;
5 -> 6 ;
7 [label=<number of examples &le; 2.32<br/>gini = 0.571<br/>samples = 21<br/>value = [1, 0, 0, 0, 1, 3, 0, 13, 3]<br/>class = SKACTIVEML_MC_EER_MISCLASS_LOSS>, fillcolor="#f191e9"] ;
5 -> 7 ;
8 [label=<number of features &le; 0.724<br/>gini = 0.667<br/>samples = 6<br/>value = [1, 0, 0, 0, 0, 1, 0, 1, 3]<br/>class = SKACTIVEML_VOI>, fillcolor="#f5b0c1"] ;
7 -> 8 ;
9 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0]<br/>class = SKACTIVEML_MC_EER_MISCLASS_LOSS>, fillcolor="#e539d7"] ;
8 -> 9 ;
10 [label=<feature dummy 3 &le; 5.14<br/>gini = 0.56<br/>samples = 5<br/>value = [1, 0, 0, 0, 0, 1, 0, 0, 3]<br/>class = SKACTIVEML_VOI>, fillcolor="#f29cb2"] ;
8 -> 10 ;
11 [label=<number of negative covariance &le; 53.22<br/>gini = 0.375<br/>samples = 4<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 3]<br/>class = SKACTIVEML_VOI>, fillcolor="#ee7b98"] ;
10 -> 11 ;
12 [label=<gini = 0.0<br/>samples = 1<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_VOI>, fillcolor="#e58139"] ;
11 -> 12 ;
13 [label=<gini = 0.0<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 3]<br/>class = SKACTIVEML_VOI>, fillcolor="#e53964"] ;
11 -> 13 ;
14 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#3964e5"] ;
10 -> 14 ;
15 [label=<number of positive covariance &le; 0.903<br/>gini = 0.338<br/>samples = 15<br/>value = [0, 0, 0, 0, 1, 2, 0, 12, 0]<br/>class = SKACTIVEML_MC_EER_MISCLASS_LOSS>, fillcolor="#eb67e0"] ;
7 -> 15 ;
16 [label=<variance mean &le; 0.16<br/>gini = 0.255<br/>samples = 14<br/>value = [0, 0, 0, 0, 1, 1, 0, 12, 0]<br/>class = SKACTIVEML_MC_EER_MISCLASS_LOSS>, fillcolor="#e957dd"] ;
15 -> 16 ;
17 [label=<entropy mean &le; 13.0<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 0, 1, 0, 0, 1, 0]<br/>class = LIBACT_QUIRE>, fillcolor="#ffffff"] ;
16 -> 17 ;
18 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0]<br/>class = SKACTIVEML_MC_EER_MISCLASS_LOSS>, fillcolor="#e539d7"] ;
17 -> 18 ;
19 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0]<br/>class = LIBACT_QUIRE>, fillcolor="#39d7e5"] ;
17 -> 19 ;
20 [label=<kurtosis mean &le; -0.014<br/>gini = 0.153<br/>samples = 12<br/>value = [0, 0, 0, 0, 0, 1, 0, 11, 0]<br/>class = SKACTIVEML_MC_EER_MISCLASS_LOSS>, fillcolor="#e74bdb"] ;
16 -> 20 ;
21 [label=<number of negative covariance &le; 49.472<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 1, 0, 1, 0]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#ffffff"] ;
20 -> 21 ;
22 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0]<br/>class = SKACTIVEML_MC_EER_MISCLASS_LOSS>, fillcolor="#e539d7"] ;
21 -> 22 ;
23 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#3964e5"] ;
21 -> 23 ;
24 [label=<gini = 0.0<br/>samples = 10<br/>value = [0, 0, 0, 0, 0, 0, 0, 10, 0]<br/>class = SKACTIVEML_MC_EER_MISCLASS_LOSS>, fillcolor="#e539d7"] ;
20 -> 24 ;
25 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0]<br/>class = SKACTIVEML_MC_EER_LOG_LOSS>, fillcolor="#3964e5"] ;
15 -> 25 ;
26 [label=<number of examples &le; 3.791<br/>gini = 0.694<br/>samples = 11<br/>value = [3, 5, 1, 0, 1, 0, 1, 0, 0]<br/>class = SKACTIVEML_VOI_UNLABELED>, fillcolor="#f5f8ce"] ;
0 -> 26 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
27 [label=<skewness mean &le; 0.039<br/>gini = 0.449<br/>samples = 7<br/>value = [0, 5, 0, 0, 1, 0, 1, 0, 0]<br/>class = SKACTIVEML_VOI_UNLABELED>, fillcolor="#e4ee7b"] ;
26 -> 27 ;
28 [label=<number of negative covariance &le; 348.103<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 0, 1, 0, 1, 0, 0]<br/>class = LIBACT_QUIRE>, fillcolor="#ffffff"] ;
27 -> 28 ;
29 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 1, 0, 0]<br/>class = LIBACT_QUIRE>, fillcolor="#8139e5"] ;
28 -> 29 ;
30 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0]<br/>class = LIBACT_QUIRE>, fillcolor="#39d7e5"] ;
28 -> 30 ;
31 [label=<gini = 0.0<br/>samples = 5<br/>value = [0, 5, 0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_VOI_UNLABELED>, fillcolor="#d7e539"] ;
27 -> 31 ;
32 [label=<variance mean &le; 0.295<br/>gini = 0.375<br/>samples = 4<br/>value = [3, 0, 1, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_VOI>, fillcolor="#eeab7b"] ;
26 -> 32 ;
33 [label=<gini = 0.0<br/>samples = 3<br/>value = [3, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_VOI>, fillcolor="#e58139"] ;
32 -> 33 ;
34 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 0]<br/>class = LIBACT_QUIRE>, fillcolor="#64e539"] ;
32 -> 34 ;
}
