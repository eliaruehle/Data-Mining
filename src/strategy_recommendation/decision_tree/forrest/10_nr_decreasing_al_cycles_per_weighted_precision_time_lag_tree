digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname="helvetica"] ;
edge [fontname="helvetica"] ;
0 [label=<number of examples &le; 3.583<br/>gini = 0.928<br/>samples = 39<br/>value = [3, 6, 1, 1, 2, 2, 1, 2, 1, 3, 1, 4, 2, 3<br/>1, 1, 2, 1, 1, 1]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#fefbf4"] ;
1 [label=<overall mean &le; 0.242<br/>gini = 0.922<br/>samples = 30<br/>value = [3, 0, 1, 1, 2, 2, 1, 2, 1, 3, 0, 4, 2, 3<br/>1, 1, 2, 0, 0, 1]<br/>class = PLAYGROUND_MIXTURE>, fillcolor="#f8f9fe"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_MIXTURE>, fillcolor="#396ae5"] ;
1 -> 2 ;
3 [label=<variance mean &le; 0.288<br/>gini = 0.926<br/>samples = 28<br/>value = [3, 0, 1, 1, 2, 2, 1, 2, 1, 3, 0, 2, 2, 3<br/>1, 1, 2, 0, 0, 1]<br/>class = PLAYGROUND_MARGIN>, fillcolor="#ffffff"] ;
1 -> 3 ;
4 [label=<feature dummy 3 &le; 7.254<br/>gini = 0.913<br/>samples = 22<br/>value = [3, 0, 1, 1, 2, 1, 1, 2, 1, 3, 0, 0, 2, 1<br/>1, 1, 2, 0, 0, 0]<br/>class = PLAYGROUND_MARGIN>, fillcolor="#ffffff"] ;
3 -> 4 ;
5 [label=<feature dummy 3 &le; 2.946<br/>gini = 0.915<br/>samples = 20<br/>value = [1, 0, 1, 1, 2, 1, 1, 2, 1, 3, 0, 0, 2, 1<br/>1, 1, 2, 0, 0, 0]<br/>class = SKACTIVEML_EXPECTED_AVERAGE_PRECISION>, fillcolor="#f4fcfe"] ;
4 -> 5 ;
6 [label=<number of features &le; 0.938<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#9e9cf2"] ;
5 -> 6 ;
7 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#3c39e5"] ;
6 -> 7 ;
8 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_EXPECTED_AVERAGE_PRECISION>, fillcolor="#39d1e5"] ;
6 -> 8 ;
9 [label=<quantile mean &le; 0.033<br/>gini = 0.913<br/>samples = 17<br/>value = [1, 0, 1, 1, 2, 1, 1, 2, 1, 2, 0, 0, 0, 1<br/>1, 1, 2, 0, 0, 0]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#ffffff"] ;
5 -> 9 ;
10 [label=<number of features &le; 0.801<br/>gini = 0.72<br/>samples = 5<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0<br/>1, 0, 2, 0, 0, 0]<br/>class = ALIPY_EXPECTED_ERROR_REDUCTION>, fillcolor="#f8ceef"] ;
9 -> 10 ;
11 [label=<number of positive covariance &le; 0.94<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0<br/>0, 0, 2, 0, 0, 0]<br/>class = ALIPY_EXPECTED_ERROR_REDUCTION>, fillcolor="#f29ce0"] ;
10 -> 11 ;
12 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 2, 0, 0, 0]<br/>class = ALIPY_EXPECTED_ERROR_REDUCTION>, fillcolor="#e539c0"] ;
11 -> 12 ;
13 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = ALIPY_UNCERTAINTY_MM>, fillcolor="#39e5c5"] ;
11 -> 13 ;
14 [label=<number of examples &le; 2.608<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>1, 0, 0, 0, 0, 0]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#ffffff"] ;
10 -> 14 ;
15 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>1, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#a339e5"] ;
14 -> 15 ;
16 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#7be539"] ;
14 -> 16 ;
17 [label=<number of negative covariance &le; 52.99<br/>gini = 0.889<br/>samples = 12<br/>value = [1, 0, 1, 1, 1, 1, 1, 2, 0, 2, 0, 0, 0, 1<br/>0, 1, 0, 0, 0, 0]<br/>class = PLAYGROUND_BANDIT>, fillcolor="#ffffff"] ;
9 -> 17 ;
18 [label=<skewness mean &le; 0.436<br/>gini = 0.75<br/>samples = 4<br/>value = [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_MC_EER_MISCLASS_LOSS>, fillcolor="#ffffff"] ;
17 -> 18 ;
19 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_MC_EER_MISCLASS_LOSS>, fillcolor="#e2e539"] ;
18 -> 19 ;
20 [label=<entropy mean &le; 168.0<br/>gini = 0.667<br/>samples = 3<br/>value = [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_INFORMATIVE_DIVERSE>, fillcolor="#ffffff"] ;
18 -> 20 ;
21 [label=<range mean &le; 0.49<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_INFORMATIVE_DIVERSE>, fillcolor="#ffffff"] ;
20 -> 21 ;
22 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#47e539"] ;
21 -> 22 ;
23 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_INFORMATIVE_DIVERSE>, fillcolor="#aee539"] ;
21 -> 23 ;
24 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#7be539"] ;
20 -> 24 ;
25 [label=<entropy mean &le; 645.5<br/>gini = 0.812<br/>samples = 8<br/>value = [1, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 1<br/>0, 1, 0, 0, 0, 0]<br/>class = PLAYGROUND_BANDIT>, fillcolor="#ffffff"] ;
17 -> 25 ;
26 [label=<number of examples &le; 2.233<br/>gini = 0.722<br/>samples = 6<br/>value = [1, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 1<br/>0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_BANDIT>, fillcolor="#ffffff"] ;
25 -> 26 ;
27 [label=<feature dummy 2 &le; 2.5<br/>gini = 0.5<br/>samples = 2<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1<br/>0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_MARGIN>, fillcolor="#ffffff"] ;
26 -> 27 ;
28 [label=<gini = 0.0<br/>samples = 1<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_MARGIN>, fillcolor="#e58139"] ;
27 -> 28 ;
29 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1<br/>0, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#6f39e5"] ;
27 -> 29 ;
30 [label=<column cosine similarity mean &le; 0.183<br/>gini = 0.5<br/>samples = 4<br/>value = [0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_BANDIT>, fillcolor="#ffffff"] ;
26 -> 30 ;
31 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_EXPECTED_AVERAGE_PRECISION>, fillcolor="#39d1e5"] ;
30 -> 31 ;
32 [label=<number of features &le; 0.573<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_BANDIT>, fillcolor="#9cf2c8"] ;
30 -> 32 ;
33 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_EXPECTED_AVERAGE_PRECISION>, fillcolor="#39d1e5"] ;
32 -> 33 ;
34 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_BANDIT>, fillcolor="#39e592"] ;
32 -> 34 ;
35 [label=<entropy mean &le; 4021.5<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0<br/>0, 1, 0, 0, 0, 0]<br/>class = SKACTIVEML_VOI_LABELED>, fillcolor="#ffffff"] ;
25 -> 35 ;
36 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 1, 0, 0, 0, 0]<br/>class = LIBACT_QUIRE>, fillcolor="#d739e5"] ;
35 -> 36 ;
37 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = SKACTIVEML_VOI_LABELED>, fillcolor="#39e55e"] ;
35 -> 37 ;
38 [label=<gini = 0.0<br/>samples = 2<br/>value = [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_MARGIN>, fillcolor="#e58139"] ;
4 -> 38 ;
39 [label=<variance mean &le; 0.352<br/>gini = 0.722<br/>samples = 6<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 2<br/>0, 0, 0, 0, 0, 1]<br/>class = PLAYGROUND_MIXTURE>, fillcolor="#ffffff"] ;
3 -> 39 ;
40 [label=<number of positive covariance &le; 0.644<br/>gini = 0.5<br/>samples = 4<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2<br/>0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_MIXTURE>, fillcolor="#ffffff"] ;
39 -> 40 ;
41 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1<br/>0, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#6f39e5"] ;
40 -> 41 ;
42 [label=<entropy mean &le; 0.5<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1<br/>0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_MIXTURE>, fillcolor="#9cb4f2"] ;
40 -> 42 ;
43 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1<br/>0, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#6f39e5"] ;
42 -> 43 ;
44 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = PLAYGROUND_MIXTURE>, fillcolor="#396ae5"] ;
42 -> 44 ;
45 [label=<feature dummy 1 &le; 526.5<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 1]<br/>class = LIBACT_DWUS>, fillcolor="#ffffff"] ;
39 -> 45 ;
46 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 1]<br/>class = ALIPY_EXPECTED_ERROR_REDUCTION>, fillcolor="#e54d39"] ;
45 -> 46 ;
47 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = LIBACT_DWUS>, fillcolor="#47e539"] ;
45 -> 47 ;
48 [label=<number of negative covariance &le; 664.711<br/>gini = 0.519<br/>samples = 9<br/>value = [0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0<br/>0, 0, 0, 1, 1, 0]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#efd083"] ;
0 -> 48 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
49 [label=<number of features &le; 0.5<br/>gini = 0.406<br/>samples = 8<br/>value = [0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0<br/>0, 0, 0, 1, 0, 0]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#ecc972"] ;
48 -> 49 ;
50 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 1, 0, 0]<br/>class = PLAYGROUND_BANDIT>, fillcolor="#e5398c"] ;
49 -> 50 ;
51 [label=<number of positive covariance &le; 0.95<br/>gini = 0.245<br/>samples = 7<br/>value = [0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#e9c15a"] ;
49 -> 51 ;
52 [label=<gini = 0.0<br/>samples = 5<br/>value = [0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#e5b439"] ;
51 -> 52 ;
53 [label=<number of features &le; 1.452<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#ffffff"] ;
51 -> 53 ;
54 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = ALIPY_DENSITY_WEIGHTED>, fillcolor="#e5b439"] ;
53 -> 54 ;
55 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0<br/>0, 0, 0, 0, 0, 0]<br/>class = LIBACT_UNCERTAINTY_SM>, fillcolor="#399de5"] ;
53 -> 55 ;
56 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0, 0, 0, 1, 0]<br/>class = ALIPY_EXPECTED_ERROR_REDUCTION>, fillcolor="#e53958"] ;
48 -> 56 ;
}
