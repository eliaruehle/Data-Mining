digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname="helvetica"] ;
edge [fontname="helvetica"] ;
0 [label=<number of examples &le; 3.791<br/>gini = 0.914<br/>samples = 39<br/>value = [3, 2, 4, 2, 1, 3, 3, 1, 7, 2, 1, 3, 2, 1<br/>3, 1]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#eef7fd"] ;
1 [label=<feature dummy 2 &le; 1.5<br/>gini = 0.906<br/>samples = 35<br/>value = [3, 2, 0, 2, 1, 3, 3, 1, 7, 2, 1, 3, 2, 1<br/>3, 1]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#e6f3fc"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<number of negative covariance &le; 48.279<br/>gini = 0.722<br/>samples = 13<br/>value = [0, 1, 0, 0, 0, 2, 0, 1, 6, 0, 0, 0, 2, 0<br/>1, 0]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#b7dbf6"] ;
1 -> 2 ;
3 [label=<quantile mean &le; 0.031<br/>gini = 0.64<br/>samples = 5<br/>value = [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0<br/>1, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#ffffff"] ;
2 -> 3 ;
4 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#39e56a"] ;
3 -> 4 ;
5 [label=<number of positive covariance &le; 0.917<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0<br/>1, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#eb9cf2"] ;
3 -> 5 ;
6 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>1, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#e53972"] ;
5 -> 6 ;
7 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0<br/>0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#d739e5"] ;
5 -> 7 ;
8 [label=<skewness mean &le; 0.497<br/>gini = 0.406<br/>samples = 8<br/>value = [0, 1, 0, 0, 0, 0, 0, 1, 6, 0, 0, 0, 0, 0<br/>0, 0]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#72b9ec"] ;
2 -> 8 ;
9 [label=<gini = 0.0<br/>samples = 6<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0<br/>0, 0]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#399de5"] ;
8 -> 9 ;
10 [label=<coefficient variation mean &le; 0.746<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0<br/>0, 0]<br/>class = PLAYGROUND_UNIFORM>, fillcolor="#ffffff"] ;
8 -> 10 ;
11 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0<br/>0, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#39dfe5"] ;
10 -> 11 ;
12 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0]<br/>class = PLAYGROUND_UNIFORM>, fillcolor="#e5c039"] ;
10 -> 12 ;
13 [label=<examples feature_ratio &le; 0.204<br/>gini = 0.905<br/>samples = 22<br/>value = [3, 1, 0, 2, 1, 1, 3, 0, 1, 2, 1, 3, 0, 1<br/>2, 1]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#ffffff"] ;
1 -> 13 ;
14 [label=<feature dummy 1 &le; 7.5<br/>gini = 0.905<br/>samples = 20<br/>value = [3, 1, 0, 2, 1, 1, 1, 0, 1, 2, 1, 3, 0, 1<br/>2, 1]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#ffffff"] ;
13 -> 14 ;
15 [label=<feature dummy 1 &le; 0.5<br/>gini = 0.847<br/>samples = 12<br/>value = [0, 1, 0, 0, 0, 1, 1, 0, 1, 2, 0, 3, 0, 0<br/>2, 1]<br/>class = OPTIMAL_GREEDY_10>, fillcolor="#f4ebfc"] ;
14 -> 15 ;
16 [label=<number of positive covariance &le; 0.87<br/>gini = 0.444<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0<br/>0, 0]<br/>class = SKACTIVEML_QUIRE>, fillcolor="#9caef2"] ;
15 -> 16 ;
17 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0<br/>0, 0]<br/>class = SKACTIVEML_QUIRE>, fillcolor="#395ee5"] ;
16 -> 17 ;
18 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0<br/>0, 0]<br/>class = SKACTIVEML_VOI_LABELED>, fillcolor="#39e5ac"] ;
16 -> 18 ;
19 [label=<number of negative covariance &le; 76.341<br/>gini = 0.79<br/>samples = 9<br/>value = [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 3, 0, 0<br/>2, 1]<br/>class = OPTIMAL_GREEDY_10>, fillcolor="#f0e3fb"] ;
15 -> 19 ;
20 [label=<feature dummy 1 &le; 2.5<br/>gini = 0.56<br/>samples = 5<br/>value = [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0<br/>0, 0]<br/>class = OPTIMAL_GREEDY_10>, fillcolor="#ca9cf2"] ;
19 -> 20 ;
21 [label=<quantile mean &le; 0.051<br/>gini = 0.375<br/>samples = 4<br/>value = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0<br/>0, 0]<br/>class = OPTIMAL_GREEDY_10>, fillcolor="#b87bee"] ;
20 -> 21 ;
22 [label=<gini = 0.0<br/>samples = 3<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0<br/>0, 0]<br/>class = OPTIMAL_GREEDY_10>, fillcolor="#9539e5"] ;
21 -> 22 ;
23 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0]<br/>class = PLAYGROUND_UNIFORM>, fillcolor="#e5c039"] ;
21 -> 23 ;
24 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0<br/>0, 0]<br/>class = SMALLTEXT_EMBEDDINGKMEANS>, fillcolor="#399de5"] ;
20 -> 24 ;
25 [label=<examples feature_ratio &le; 0.045<br/>gini = 0.625<br/>samples = 4<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0<br/>2, 1]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#f6bdd0"] ;
19 -> 25 ;
26 [label=<examples feature_ratio &le; 0.028<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 1]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#ffffff"] ;
25 -> 26 ;
27 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 1]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#e53f39"] ;
26 -> 27 ;
28 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0]<br/>class = SKACTIVEML_QBC_VOTE_ENTROPY>, fillcolor="#39e56a"] ;
26 -> 28 ;
29 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>2, 0]<br/>class = PLAYGROUND_KCENTER_GREEDY>, fillcolor="#e53972"] ;
25 -> 29 ;
30 [label=<number of features &le; 1.511<br/>gini = 0.75<br/>samples = 8<br/>value = [3, 0, 0, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1<br/>0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#fbeade"] ;
14 -> 30 ;
31 [label=<entropy mean &le; 36.0<br/>gini = 0.375<br/>samples = 4<br/>value = [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0<br/>0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#eeab7b"] ;
30 -> 31 ;
32 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0<br/>0, 0]<br/>class = SKACTIVEML_QUIRE>, fillcolor="#5639e5"] ;
31 -> 32 ;
33 [label=<gini = 0.0<br/>samples = 3<br/>value = [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0]<br/>class = OPTIMAL_GREEDY_20>, fillcolor="#e58139"] ;
31 -> 33 ;
34 [label=<entropy mean &le; 3024.5<br/>gini = 0.625<br/>samples = 4<br/>value = [0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1<br/>0, 0]<br/>class = SMALLTEXT_RANDOM>, fillcolor="#d8f6bd"] ;
30 -> 34 ;
35 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0]<br/>class = SMALLTEXT_RANDOM>, fillcolor="#89e539"] ;
34 -> 35 ;
36 [label=<variance mean &le; 0.294<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1<br/>0, 0]<br/>class = PLAYGROUND_GRAPH_DENSITY>, fillcolor="#ffffff"] ;
34 -> 36 ;
37 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1<br/>0, 0]<br/>class = ALIPY_RANDOM>, fillcolor="#e539b4"] ;
36 -> 37 ;
38 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0]<br/>class = PLAYGROUND_GRAPH_DENSITY>, fillcolor="#47e539"] ;
36 -> 38 ;
39 [label=<gini = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0<br/>0, 0]<br/>class = SKACTIVEML_VOI_LABELED>, fillcolor="#39e5ac"] ;
13 -> 39 ;
40 [label=<gini = 0.0<br/>samples = 4<br/>value = [0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0<br/>0, 0]<br/>class = OPTIMAL_GREEDY_10>, fillcolor="#c8e539"] ;
0 -> 40 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
}
